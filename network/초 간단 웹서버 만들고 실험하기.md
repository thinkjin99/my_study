### 개요
* 파이썬으로 만드는 웹서버
* 웹 서버의 동작 방식
* 코드 분석
* 멀티 쓰레드 VS 싱글-비동기
* 이슈 해결
___
### 파이썬으로 만드는 웹 서버

이하에서는 [[싱글 스레드 기반의 초간단 정적 웹서버 만들기]] 명세에 적혀있는 조건을 만족하는 파이썬 코드를 설명한다. 해당 프로젝트에서 요구하는 조건은 아래와 같다.

* 내장 라이브러리만 사용할 것
* 싱글 쓰레드로 동시접속을 구현할 것
* 유저의 요청은 concurrent하게 처리 될것
* 이벤트 루프 구조를 활용할 것

내장 라이브러리 중 asyncio나 http.server를 활용하는 방법도 존재하지만, 소켓을 통해 구현하는 방식이 웹 서버의 기본적인 원리를 파악하기에 적합 하기에 소켓을 활용해 코드를 작성했다. 
___
### 주요 데이터 모델

#### 커넥션

```python
@dataclass
class Connection:
    event: select.kevent
    sock: socket.socket
    requests: list[Generator]
```

**커넥션 객체는 클라이언트와의 커넥션을 나타내며 HTTP의 지속 커넥션을 사용하기 위해 활용한다.** 

event는 커넥션이 담당하는 kevent 객체를 담당한다. kevent는 kqueue에 등록하는 이벤트 객체로 발생한 이벤트 타입이나 이벤트가 발생한 fd 등의 정보를 포함하고 있다. (이곳에서는 read 이벤트만 구독한다)

sock은 소켓 객체로 실제 데이터를 송,수신하는 커넥션을 의미한다. 

requests는 사용자가 전송한 요청을 의미하며 이곳에는 아직 종료되지 않고 대기중이거나 실행되지 않은 요청들이 저장된다.
___
### 동작 방식

해당 코드는 이벤트 루프를 활용해 싱글 쓰레드에서 멀티 IO를 구현한다. 아래의 코드를 보자.
```python
def async_main():
    listen_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    listen_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    listen_sock.bind(("127.0.0.1", 8080))
    listen_sock.listen(100)

    kq = select.kqueue()
    server_event = select.kevent(
        listen_sock.fileno(), select.KQ_FILTER_READ, select.KQ_EV_ADD
    )
    kq.control([server_event], 0)

    connections: Dict[int, Connection] = {}  # 커넥션 풀

    while True:
        events = kq.control(None, 100, 0.1)  # 최대 100개의 이벤트 등록 0.1초마다 큐 확인
        for event in events:
            if listen_sock.fileno() == event.ident:
                client_sock, _ = listen_sock.accept()
                peer = client_sock.getpeername()
                logging.info(f"Connection Socket: {peer[1]} is connected")

                client_event = select.kevent(
                    client_sock.fileno(), select.KQ_FILTER_READ, select.KQ_EV_ADD
                )  # read를 등록하고 큐에 추가하는 이벤트 생성

                kq.control([client_event], 0)  # 큐에 커넥션을 등록
                connections[client_sock.fileno()] = Connection(
                    sock=client_sock, event=client_event, requests=[]
                )  # 커넥션 풀에 커넥션 등록

            elif event.filter == select.KQ_FILTER_READ:
                request = server(connections[event.ident])  # 요청 제네레이터
                connections[event.ident].requests.append(request)

        remove_fds = run_requests(connections) #대기중인 작업 실행
        remove_connection(kq, remove_fds, connections)  # 종료된 연결 삭제
```

이는 코드의 핵심 로직으로 사용하는 이벤트 루프 전체를 나타낸다. 이벤트 루프의 동작 순서는 다음과 같다.
 1. kqueue에서 발생한 이벤트를 추출한다
 2. 추출한 이벤트의 타입을 검사한다
 3. 발생한 이벤트에 따라 적절한 처리를 진행한다
 4. 대기중인 작업들을 실행한다
 5. 처리가 완료된 리퀘스트나 소켓을 제거한다

#### 발생한 이벤트를 추출
이벤트의 추출은 kqueue에서 자동적으로 처리해준다. 이는 mac OS에서 구현한 기능으로 특정한 fd에서 감지하고 싶은 이벤트 타입을 등록할 경우 OS단에서 이를 감지하다 이벤트가 발생했을 때 큐에서 추출해 준다.
이는 [[IO Multiplexing#epoll|epoll]]과 흡사한 방법으로 동작하며, 일전에 살펴본 [[IO Multiplexing#select|select]]와 달리 비지 웨이팅하지 않는 방식으로 동작한다. 

<span class="red red-bg">따라서 kqueue에서는 각각의 커넥션에서 도착한 메시지가 존재하는지 비지 웨이팅하지 않고 주기적으로 큐만 확인을 하고 큐에 존재하는 이벤트만 추출 해준다.</span>

이 복잡한 과정을 전부 `events = kq.control(None, 100, 0.1)` 라는 한줄로 처리 할 수 있다. 해당 코드는 0.1초 동안 블락을 진행하고 큐에 이벤트가 발생 하기를 대기한다. 이후 이벤트가 발생했을 경우 반환한다. 0.1초 동안 이벤트가 발생하지 않았을 경우 빈 배열을 돌려준다.

#### 이벤트 타입 검사 및 처리
해당 코드에서 사용하는 이벤트는 전부 읽기 이벤트로 큐도 읽기 이벤트만 구독한다. 읽기 이벤트가 발생하는 곳은 서버 소켓과 클라이언트 소켓 두개로 서버 소켓에서 이벤트가 발생한 경우 신규 커넥션을 생성 해준다. 

만약 서버 소켓이 아닌 곳에서 이벤트가 발생했을 경우 리퀘스트가 발생한 것이므로 기존에 존재하던 커넥션에 리퀘스트를 추가 해준다.

```python
if listen_sock.fileno() == event.ident:
	client_sock, _ = listen_sock.accept()
	peer = client_sock.getpeername()
	logging.info(f"Connection Socket: {peer[1]} is connected")

	client_event = select.kevent(
		client_sock.fileno(), select.KQ_FILTER_READ, select.KQ_EV_ADD
	)  # read를 등록하고 큐에 추가하는 이벤트 생성

	kq.control([client_event], 0)  # 큐에 커넥션을 등록
	connections[client_sock.fileno()] = Connection(
		sock=client_sock, event=client_event, requests=[]
	)  # 커넥션 풀에 커넥션 등록

elif event.filter == select.KQ_FILTER_READ:
	request = server(connections[event.ident])  # 요청 제네레이터
	connections[event.ident].requests.append(request)

```

요청의 처리 자체는 `server` 함수에서 처리 된다. 
```python
def server(Connection: Connection):
    start_line = None
    client_sock = Connection.sock

    try:
        msg = read_data(Connection.sock)
        if not msg: #커넥션이 종료된 경우
            return Connection

        logging.info(msg + "\n")
        start_line, *_ = msg.split("\r")  # 메시지 파싱

    except (ConnectionResetError, OSError):
        logging.info(f"Connection reset connection...")
        return Connection

    if start_line:
        method, path, version = start_line.split()
        response_msg = create_response(method, path)

        start = time.time()
        hold_time = random.randint(1, 3)

        # 인위적으로 생성한 시간이 소요되는 프로세스
        while True:
            now = time.time()
            print("Server waits...")
            if now - start >= hold_time:
                break
            yield 0  # 0은 커넥션이 살아있음

        client_sock.send(response_msg.encode("utf-8"))

    return 0
```

서버 함수는 사용자의 메시지를 확인해 메시지가 비거나 연결이 초기화 됐을 경우 연결 종료를 위해 커넥션 객체를 반환한다. 만약 메시지가 정상적으로 수신이 됐을 경우에는 파싱을 진행해 요청 메시지를 해석하고 적절한 응답을 반환한다. 

해당 함수의 중요한 부분은 `while` 문 내부에서 반복적으로 **특정한 시간이 될 때까지 비지 웨이팅을 하는 로직**이다. 이 부분은 제네레이터로 구현돼 있는데 **이렇게 작성 함으로써 실행흐름을 온전히 블락하지 않고 여러 요청을 처리하는 것이 가능**해진다.
#### 대기중인 작업 실행
이벤트 처리를 진행한 이후에는 이전에 수행을 전부 끝내지 못한 리퀘스트를 마저 처리 해준다. `run_requests` 함수에서 이를 처리하며 `next(server)`를 통해 제네레이터를 반복 하는 방식으로 작업을 진행한다.

함수는 모든 리퀘스트를 순회하며 각 리퀘스트에 할당된 `server` 제네레이터를 `yield`를 만날 때까지 실행한다. 이때 반환되는 값을 확인해 리퀘스트의 대기가 종료 됐는지 확인하고 종료된 리퀘스트는 제거하는 작업을 수행 해준다. 또한 종료된 커넥션 또한 감지해 삭제할 리스트에 포함시켜 반환한다.

```python
def run_requests(connections: dict[int, Connection]) -> list[int]:
    remove_fds = [] #종료할 커넥션
    for key, Connection in connections.items():
        finished_requests = set()  # 종료된 요청
        for req in Connection.requests:
            try:
                if req:
                    next(req)  # 대기 중인 작업 재실행

            except StopIteration as e:
                if e.value:
                    remove_fds.append(key)  # 종료할 커넥션
                finished_requests.add(req)

        Connection.requests = [
            req for req in Connection.requests if req not in finished_requests
        ]  # 완료된 작업 삭제

    return remove_fds
```

#### 처리가 완료된 소켓을 제거한다
모든 대기중인 작업을 처리한 이후로는 연결이 종료된 커넥션을 닫고 종료된 이벤트들을 큐에서 제거한다. 
```python
def remove_connection(
    kq: select.kqueue, remove_fds: list[int], connections: dict[int, Connection]
):
    for fd in remove_fds:
        closed_connection = connections[fd]
        kq.control(
            [
                select.kevent(
                    closed_connection.event.ident,
                    select.KQ_FILTER_READ,
                    select.KQ_EV_DELETE,
                )
            ],
            0,
        )  # 커넥션을 큐에서 제거한다.
        closed_connection.sock.close()  # 커넥션 닫기
        logging.info(f"\n{closed_connection.sock} is closed\n")
        del connections[fd]  # 커넥션 풀에서 제거한다.
```
____
### 멀티 쓰레드 VS 비동기

동일한 로직으로 동작하는 멀티 쓰레드 코드와 비동기-논블락킹 코드의 퍼포먼스를 비교해보자. 비교를 위해 사용한 클라이언트 코드는 아래와 같다.
```python
import socket
import time
import concurrent.futures


def send_recv(sock: socket.socket | None = None):
    request_msg = """GET / HTTP/1.1\r\nHost: 127.0.0.1:8080\r\n\r\n"""
    start = time.time()

    if not sock:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        sock.connect(("127.0.0.1", 8080))
        sock.send(request_msg.encode("utf-8"))
	    resp = sock.recv(512)
	    sock.close()
	
	else:
	    sock.send(request_msg.encode("utf-8"))
	    resp = sock.recv(512)

    print("resp: ", resp[:10])
    end = time.time()

    return end - start


if __name__ == "__main__":
    with concurrent.futures.ThreadPoolExecutor(max_workers=32) as executor:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        sock.connect(("127.0.0.1", 8080))
        futures = [executor.submit(send_recv) for _ in range(100)]  # no reuse
        # futures = [executor.submit(send_recv, sock) for _ in range(100)]  # yes reuse

        total = 0
        start = time.time()
        for i, f in enumerate(concurrent.futures.as_completed(futures), start=1):
            print(f"{i} is completed Sec: {f.result()}")
            total += f.result()

    print("close socket")
    if sock:
        sock.close()

    end = time.time()
    print(f"Total:{end-start}, avg sec: {total / 100}")

```

 클라이언트는 멀티 쓰레딩을 활용해 비동기로 여러 개의 요청을 서버에 전송하는 방식으로 동작한다. 클라이언트는 하나의 커넥션을 지속해서 사용하는 지속 커넥션 기능을 사용할 수 있으며 이 경우 하나의 커넥션으로 모든 리퀘스트를 전송한다.
 
구현 방법 별로 서버의 성능 차이는 이 정도 발생했다. 아래는 리퀘스트 요청 수 별 총 소요시간과 평균 소요시간을 나타낸 표이다. 해당 성능은 지속 커넥션을 사용하지 않았을 때의 측정 결과이다.

| 타입       | 요청 수 | 전체 소요시간 | 평균 소요시간 |
| -------- | ---- | ------- | ------- |
| 비동기-논블락킹 | 100  | 8       | 2       |
| 비동기-논블락킹 | 1000 | 16      | 2       |
| 멀티 쓰레딩   | 100  | 16      | 4.3     |
| 멀티 쓰레딩   | 1000 | 144     | 4.5     |
왜 멀티 쓰레딩 방식의 웹 서버가 2배 가까이 딜레이가 발생할까? 이유 파악을 위해 멀티 쓰레딩 방식 서버의 코드를 간략하게 살펴보자.

```python
def main():
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

    sock.bind(("127.0.0.1", 8080))
    sock.listen(100)
    print("Server is running...")
    with ThreadPoolExecutor(max_workers=16) as executor: #쓰레드 풀 생성
        executor.submit(log_worker) #로깅
        while True:
            client_sock, _ = sock.accept()
            log_queue.put(
                f"Connected {client_sock.getsockname()} >> {client_sock.getpeername()}\n"
            )
            executor.submit(server, client_sock)
```

멀티 쓰레딩 서버는 쓰레드를 16개 생성해 값을 처리하는 방식으로 동작한다. 이때 사**용 가능한 쓰레드가 없을 경우 연결이 할당되지 못하고 다른 쓰레드가 종료 될 때까지 대기하는 현상이 발생한다. 또한 쓰레드를 반납하고 다시 할당해주는 작업에서도 오버헤드가 발생**한다.

또한 한번에 작업을 처리할 수 있는 **쓰레드의 수가 16개 인근으로 한정 되기 때문에 32개씩 전송되는 요청을 절반씩 밖에 처리하지 못하는 불상사가 발생**하게 된다. 실제로 파이썬 코드 내부에서 `threading.active_count()` 를 확인해보면 20~21 정도의 쓰레드만 실행되는 것을 확인할 수 있다. (쓰레드의 수가 어느정도 초과할 수도 있다)

반면 **비동기 서버의 경우 평균적으로 30~33개 까지의 요청을 한번에 처리하는 것을 확인할 수 있었다. 비동기의 경우 쓰레드와 달리 수 제한이 존재하지 않고 들어오는 모든 요청을 큐에 등록 하므로 32개씩 전송하는 클라이언트의 요청이 거진 모두 동시에 처리**된다고 볼 수 있다.

| 타입    | 평균 처리수 |
| ----- | ------ |
| 비동기   | 32     |
| 멀티쓰레드 | 21     |

> [!info]
> **멀티 쓰레드가 한번에 핸들링 하는 커넥션의 양이 더 적기 때문에 멀티 쓰레드의 속도가 비동기 보다 저하되는 문제가 발생한다.**

#### 그럼 쓰레드 수를 늘려!
아주 직관적인 의견이다 서버의 처리 속도를 높이기 위해선 서버에서 사용하는 쓰레드의 수를 증가 시키면 되지 않을까? 이상적인 쓰레드 수는 요청을 보내는 속도에 맞춰서 처리가 가능할 정도의 양일 것이다.<span class="red red-bg"> 문제는 보내는 요청의 수에 비해 쓰레드는 그렇게 까지 확대될 수 없다는 문제가 존재한다.</span>

파이썬 자체에서 권장하는 쓰레드의 수는 `min(32, os.cpu_count() + 4)` 정도로 많아봐야 32개 정도이고 일반적인 현대 시스템에선 아무리 많아야 수천 개 정도의 쓰레드가 한계라고 한다.

> A sensible **upper limit for many applications is hundreds of threads to perhaps a few thousand threads**. More than a few thousand threads on a modern system may result in too much context switching, depending on your system and on the types of tasks that are being executed. [참고](https://superfastpython.com/threadpoolexecutor-number-of-threads/)

만약 쓰레드가 이보다 많을 경우 컨텍스트 스위칭 비용 등이 더욱 크게 발생해 역으로 비효율이 발생할 수도 있다. **요청 수에 비례해서 쓰레드를 늘리는 것에는 한계가 있기 때문에 멀티 쓰레딩 방식의 서버에서 쓰레드의 증가로만 성능을 개선 시키기에는 문제가 존재**한다.

이러한 문제점들로 인해 대규모 IO 작업이 필요한 경우 멀티 쓰레드보다 비동기 서버가 더욱 유리할 수 있다. ([[멀티 스레딩#비동기-싱글 쓰레드는 왜 쓰나요?|비동기 싱글 스레드가 좋은 이유]])